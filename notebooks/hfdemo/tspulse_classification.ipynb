{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a91f5c-0f2f-4786-be43-b4e6e74d86c0",
   "metadata": {},
   "source": [
    "\n",
    "# Getting Started with TSPulse Classification\n",
    "\n",
    "This notebook demonstrates the usage of a pre-trained TSPulse model for time-series classification task. Refer to [TSPulse](https://arxiv.org/abs/2505.13033) paper for architecture and other details.\n",
    "\n",
    "Backbone of the pre-trained model is freezed and the classifier head along with the input patch embedding layer is finetuned on the classification dataset.\n",
    "\n",
    "The pre-trained TSPulse model can be accessed from the [Hugging Face TSPulse Model Repository](https://huggingface.co/ibm-granite/granite-timeseries-tspulse-r1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d0025-e9dd-465f-a45a-2ecc22073328",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ccc6220-6a78-4aa1-b3ac-737223dbe987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments, set_seed\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "from transformers.trainer_utils import RemoveColumnsCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af924e6-1ee2-489c-9bfc-b5d151a003c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee950055-4527-40eb-8fe2-ce023003f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the current notebook's directory.\n",
    "# This makes the code work no matter where you launch jupyter from.\n",
    "notebook_dir = os.path.abspath(os.path.dirname(''))\n",
    "\n",
    "# Assuming the 'tsfm_public' library is in a subdirectory called 'granite-tsfm'\n",
    "# located in the same root as the notebook.\n",
    "# This constructs the full path to the library.\n",
    "project_root = os.path.dirname(notebook_dir) # Go up one level if notebook is in a subfolder\n",
    "tsfm_public_path = os.path.join(project_root, \"..\")\n",
    "\n",
    "# Add the library's parent directory to the system path\n",
    "# We add the parent so that python can resolve `from tsfm_public...`\n",
    "if tsfm_public_path not in sys.path:\n",
    "    print(f\"Adding {tsfm_public_path} to system path\")\n",
    "    sys.path.insert(0, tsfm_public_path)\n",
    "\n",
    "from tsfm_public.models.tspulse import TSPulseForClassification\n",
    "from tsfm_public.toolkit.dataset import ClassificationDFDataset\n",
    "from tsfm_public.toolkit.lr_finder import optimal_lr_finder\n",
    "from tsfm_public.toolkit.time_series_classification_preprocessor import TimeSeriesClassificationPreprocessor\n",
    "from tsfm_public.toolkit.util import convert_tsfile_to_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aba832-beab-442f-a6e7-a70abbfdfbc1",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3eedad-946d-41fa-b2c2-838307091d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938db5cc-a761-4eb7-9042-e42aa8075a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"BasicMotions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503186b9-99aa-4335-a966-e3dc9a24414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Use Relative Paths for Portability ---\n",
    "\n",
    "# The dataset directory is relative to the current notebook's location.\n",
    "dataset_dir = \"Multivariate_ts\"\n",
    "\n",
    "# Construct the relative paths to the train and test files\n",
    "path = os.path.join(dataset_dir, dataset_name, f\"{dataset_name}_TRAIN.ts\")\n",
    "\n",
    "df_base = convert_tsfile_to_dataframe(\n",
    "    path,\n",
    "    return_separate_X_and_y=False,\n",
    ")\n",
    "\n",
    "label_column = \"class_vals\"\n",
    "input_columns = [f\"dim_{i}\" for i in range(df_base.shape[1] - 1)]\n",
    "\n",
    "tsp = TimeSeriesClassificationPreprocessor(\n",
    "    input_columns=input_columns,\n",
    "    label_column=label_column,\n",
    "    scaling=True,\n",
    ")\n",
    "\n",
    "tsp.train(df_base)\n",
    "df_train_prep = tsp.preprocess(df_base)\n",
    "\n",
    "base_dataset = ClassificationDFDataset(\n",
    "    df_train_prep,\n",
    "    id_columns=[],\n",
    "    timestamp_column=None,\n",
    "    input_columns=input_columns,\n",
    "    label_column=label_column,\n",
    "    context_length=512,\n",
    "    static_categorical_columns=[],\n",
    "    stride=1,\n",
    "    enable_padding=False,\n",
    "    full_series=True,\n",
    ")\n",
    "\n",
    "path = os.path.join(dataset_dir, dataset_name, f\"{dataset_name}_TEST.ts\")\n",
    "\n",
    "df_test = convert_tsfile_to_dataframe(\n",
    "    path,\n",
    "    return_separate_X_and_y=False,\n",
    ")\n",
    "\n",
    "label_column = \"class_vals\"\n",
    "input_columns = [f\"dim_{i}\" for i in range(df_test.shape[1] - 1)]\n",
    "\n",
    "df_test_prep = tsp.preprocess(df_test)\n",
    "\n",
    "test_dataset = ClassificationDFDataset(\n",
    "    df_test_prep,\n",
    "    id_columns=[],\n",
    "    timestamp_column=None,\n",
    "    input_columns=input_columns,\n",
    "    label_column=label_column,\n",
    "    context_length=512,\n",
    "    static_categorical_columns=[],\n",
    "    stride=1,\n",
    "    enable_padding=False,\n",
    "    full_series=True,\n",
    ")\n",
    "\n",
    "\n",
    "# creating a validation set\n",
    "\n",
    "dataset_size = len(base_dataset)\n",
    "print(dataset_size)\n",
    "split_valid_ratio = 0.1\n",
    "val_size = int(split_valid_ratio * dataset_size)  # 10% valid split\n",
    "train_size = dataset_size - val_size\n",
    "train_dataset, valid_dataset = random_split(base_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0976700-08fc-42c6-8dab-c1134c0fcc21",
   "metadata": {},
   "source": [
    "## Configs for the TSPulse model\n",
    "### Hyperparameters to Optimize and suggested values :\n",
    "#### head_reduce_d_model = 1, 2\n",
    "#### decoder_mode = mix_channel, common_channel\n",
    "#### head_gated_attention_activation = softmax, sigmoid\n",
    "#### mask_ratio = 0, 0.3\n",
    "#### channel_virtual_expand_scale = 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07694897-1fa7-46d5-8b01-71af52a5a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"head_gated_attention_activation\": \"softmax\",\n",
    "    \"channel_virtual_expand_scale\": 2,\n",
    "    \"mask_ratio\": 0.3,\n",
    "    \"head_reduce_d_model\": 1,\n",
    "    \"disable_mask_in_classification_eval\": True,\n",
    "    \"fft_time_consistent_masking\": True,\n",
    "    \"decoder_mode\": \"mix_channel\",\n",
    "    \"head_aggregation_dim\": \"patch\",\n",
    "    \"head_aggregation\": None,\n",
    "    \"loss\": \"cross_entropy\",\n",
    "    \"ignore_mismatched_sizes\": True,\n",
    "}\n",
    "\n",
    "config_dict[\"num_input_channels\"] = tsp.num_input_channels\n",
    "config_dict[\"num_targets\"] = df_base[\"class_vals\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48a3aa-10bb-476d-a0bf-c20b47f286d7",
   "metadata": {},
   "source": [
    "## Getting the Pretrained Model with above configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7a221-91b7-4bfb-b397-ffc441746786",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSPulseForClassification.from_pretrained(\n",
    "    \"ibm-granite/granite-timeseries-tspulse-r1\", revision=\"tspulse-block-dualhead-512-p16-r1\", **config_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcd1b1-6e88-4359-9214-882e6e7ffea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "# model = model.to(device).float()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15e12599-c519-49b4-9e5b-d32dfec912e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing Backbone except patch embedding layer....\n",
    "\n",
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.backbone.time_encoding.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.backbone.fft_encoding.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03211294-ff0d-4358-aa43-dd024387f2e1",
   "metadata": {},
   "source": [
    "## Finetuning the classifier head and patch embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "873aecaf-b329-4bc8-a72b-40989bd9a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = \"tspulse_finetuned_models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4ab6a-ee7b-4602-b207-b0cb9dc3ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "suggested_lr = None\n",
    "\n",
    "train_dict = {\"per_device_train_batch_size\": 32, \"num_train_epochs\": 200, \"eval_accumulation_steps\": None}\n",
    "\n",
    "EPOCHS = train_dict[\"num_train_epochs\"]\n",
    "BATCH_SIZE = train_dict[\"per_device_train_batch_size\"]\n",
    "eval_accumulation_steps = train_dict[\"eval_accumulation_steps\"]\n",
    "NUM_WORKERS = 1\n",
    "NUM_GPUS = 1\n",
    "\n",
    "set_seed(42)\n",
    "if suggested_lr is None:\n",
    "    lr, model = optimal_lr_finder(\n",
    "        model,\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "    suggested_lr = lr\n",
    "print(\"Suggested LR : \", suggested_lr)\n",
    "finetune_args = TrainingArguments(\n",
    "    output_dir=temp_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=suggested_lr,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    eval_accumulation_steps=eval_accumulation_steps,\n",
    "    dataloader_num_workers=NUM_WORKERS,\n",
    "    report_to=\"tensorboard\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    logging_dir=os.path.join(OUT_DIR, \"output\"),  # Make sure to specify a logging directory\n",
    "    load_best_model_at_end=True,  # Load the best model when training ends\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "    greater_is_better=False,  # For loss\n",
    ")\n",
    "\n",
    "# Create the early stopping callback\n",
    "early_stopping_callback = EarlyStoppingCallback(\n",
    "    early_stopping_patience=100,  # Number of epochs with no improvement after which to stop\n",
    "    early_stopping_threshold=0.0001,  # Minimum improvement required to consider as improvement\n",
    ")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=suggested_lr)\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    suggested_lr,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=math.ceil(len(train_dataset) / (BATCH_SIZE * NUM_GPUS)),\n",
    ")\n",
    "\n",
    "finetune_trainer = Trainer(\n",
    "    model=model,\n",
    "    args=finetune_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    optimizers=(optimizer, scheduler),\n",
    ")\n",
    "\n",
    "# Fine tune\n",
    "finetune_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d63f9-1bcf-457b-a582-7453f9ab2716",
   "metadata": {},
   "source": [
    "## Classification Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dce5c3-33ad-4859-99d2-0ef7e54e76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dict = finetune_trainer.predict(test_dataset)\n",
    "preds_np = predictions_dict.predictions[0]\n",
    "\n",
    "remove_columns_collator = RemoveColumnsCollator(\n",
    "    data_collator=default_data_collator,\n",
    "    signature_columns=[\"target_values\"],\n",
    "    logger=None,\n",
    "    description=None,\n",
    "    model_name=\"temp\",\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=remove_columns_collator)\n",
    "target_list = []\n",
    "for batch in test_dataloader:\n",
    "    batch_labels = batch[\"target_values\"].numpy()\n",
    "    target_list.append(batch_labels)\n",
    "targets_np = np.concatenate(target_list, axis=0)\n",
    "test_accuracy = np.mean(targets_np == np.argmax(preds_np, axis=1))\n",
    "print(\"test_accuracy : \", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2877ed8-26de-42b8-9430-3b5d652ea1af",
   "metadata": {},
   "source": [
    "## Using Classification Pipeline for inference with the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bc81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfm_public.toolkit.time_series_classification_pipeline import TimeSeriesClassificationPipeline\n",
    "\n",
    "\n",
    "pipe = TimeSeriesClassificationPipeline(finetune_trainer.model, feature_extractor=tsp, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993670a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3355f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsb-ad-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
